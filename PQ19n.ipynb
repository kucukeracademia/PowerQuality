{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PQ19n.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "_vgwUnJuv6Uc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AmkNajnLvxfb"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display\n",
        "\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from keras.utils import np_utils\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, MaxPool2D\n",
        "from keras.layers import AvgPool2D, BatchNormalization, Reshape, Activation\n",
        "from keras.optimizers import Adadelta, RMSprop, Adam\n",
        "from keras import backend as K\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "import tensorflow as tf\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "folder=\"/content/drive/My Drive/Colab Notebooks/PQ19/data/\""
      ],
      "metadata": {
        "id": "6VOlQFVMv9u_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(folder+'df191.csv')\n",
        "df = shuffle(df)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "jyvU6urfwEg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=df.values"
      ],
      "metadata": {
        "id": "XsJcl7fEwFON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=dataset[:26600,1:2001]\n",
        "Y_train=dataset[:26600,0]\n",
        "X_val=dataset[26600:30400,1:2001]\n",
        "Y_val=dataset[26600:30400,0]\n",
        "X_test=dataset[30400:38000,1:2001]\n",
        "Y_test=dataset[30400:38000,0]\n",
        "print(X_train.shape, X_val.shape, X_test.shape, Y_train.shape, Y_val.shape, Y_test.shape )"
      ],
      "metadata": {
        "id": "3qxhguq7wM7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import collections, numpy\n",
        "collections.Counter(Y_val)"
      ],
      "metadata": {
        "id": "Ea5eviiFwceO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DCNN"
      ],
      "metadata": {
        "id": "uEfvDMtJyRqi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_rows = 40\n",
        "img_cols = 50\n",
        "\n",
        "X_train1 = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
        "X_val1 = X_val.reshape(X_val.shape[0], img_rows, img_cols, 1)\n",
        "X_test1 = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
        "print(X_train1.shape, X_val1.shape, X_test1.shape, Y_train.shape, Y_val.shape, Y_test.shape )\n",
        "\n",
        "input_shape = (img_rows, img_cols, 1)"
      ],
      "metadata": {
        "id": "kCenzBBhwvgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "activation='relu'\n",
        "\n",
        "def create_model():\n",
        "  model = Sequential()   \n",
        "  model.add(Conv2D(128, kernel_size=(3, 3), activation=activation, input_shape=input_shape)) \n",
        "  model.add(MaxPooling2D(2,2))\n",
        "\n",
        "  model.add(Conv2D(64, (3, 3), activation=activation))\n",
        "  model.add(MaxPooling2D(2,2))\n",
        "\n",
        "  model.add(Conv2D(64, kernel_size=(3, 3), activation=activation, input_shape=input_shape)) \n",
        "  model.add(MaxPooling2D(2,2))\n",
        "\n",
        "  model.add(Flatten())\n",
        "\n",
        "  model.add(Dense(256, activation=activation))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dense(19, activation='softmax'))\n",
        "\n",
        "  model.compile(loss='sparse_categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
        "\n",
        "  return model\n",
        "\n"
      ],
      "metadata": {
        "id": "xsw-bb_0wwLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "model_ckpt= create_model()\n",
        "checkpoint_path = \"/content/drive/My Drive/Colab Notebooks/PQ19/data/cp191.ckpt\"\n",
        "cp_callback = ModelCheckpoint(filepath=checkpoint_path,save_best_only=True, save_weights_only=True, verbose=1)\n",
        "\n",
        "model_ckpt.summary()"
      ],
      "metadata": {
        "id": "m1GxXZuUxTcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKO5T4lW5VFQ"
      },
      "source": [
        "batchsize = 100\n",
        "epochs = 1000\n",
        "\n",
        "hist=model_ckpt.fit(X_train1, Y_train, batch_size=batchsize, epochs=epochs, validation_data=(X_val1, Y_val),callbacks=[cp_callback], verbose=1)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')  \n",
        "plt.legend(['Train', 'Val'], loc='upper right')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(hist.history['accuracy'])\n",
        "plt.plot(hist.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Un-nlA9nxxkW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get the latest checkpoint file\n",
        "\n",
        "model_latest_checkpoint = create_model()\n",
        "# Load the previously saved weights\n",
        "model_latest_checkpoint.load_weights(checkpoint_path)"
      ],
      "metadata": {
        "id": "gKxZiCHgx5Xb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "acc = model_latest_checkpoint.evaluate(X_test1, Y_test)\n",
        "print(\"Loss:\", acc[0], \" Accuracy:\", acc[1])\n",
        "\n",
        "pred = model_latest_checkpoint.predict(X_test1)\n",
        "y_pred = pred.argmax(axis=-1)\n",
        "y_true = Y_test"
      ],
      "metadata": {
        "id": "34TWRqZcx7qu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_classes=['C1','C2','C3','C4','C5','C6','C7','C8','C9','C10','C11','C12','C13','C14','C15','C16','C17','C18','C19']\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, classifier_name):\n",
        "    mtx = confusion_matrix(y_true, y_pred)\n",
        "    fig, ax = plt.subplots(figsize=(20,20))\n",
        "    ax.set_title(classifier_name)\n",
        "    sns.heatmap(mtx, xticklabels= output_classes, yticklabels=output_classes, cmap=\"Blues\", annot=True, fmt='d', linewidths=.5,  cbar=False, ax=ax)\n",
        "    #  square=True,\n",
        "    plt.ylabel('true label')\n",
        "    plt.xlabel('predicted label')"
      ],
      "metadata": {
        "id": "MOzYs8ckx-mI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(y_true, y_pred, classifier_name='DCNN')\n",
        "print(classification_report(y_true, y_pred,digits=4))\n",
        "acc_cnn1 = accuracy_score(y_true, y_pred)\n",
        "print(acc_cnn1)"
      ],
      "metadata": {
        "id": "97xYO6TjyEnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DLSTM"
      ],
      "metadata": {
        "id": "qeqmLYVvyMnK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_rows = 40\n",
        "img_cols = 50\n",
        "\n",
        "X_train1 = X_train.reshape(X_train.shape[0], img_rows, img_cols)\n",
        "X_val1 = X_val.reshape(X_val.shape[0], img_rows, img_cols)\n",
        "X_test1 = X_test.reshape(X_test.shape[0], img_rows, img_cols)\n",
        "print(X_train1.shape, X_val1.shape, X_test1.shape, Y_train.shape, Y_val.shape, Y_test.shape )\n",
        "\n",
        "input_shape = (img_rows, img_cols)"
      ],
      "metadata": {
        "id": "jibTa0RkyJFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "activation='relu'\n",
        "\n",
        "def lstm_model_1(activation):\n",
        "    \n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(tf.compat.v1.keras.layers.CuDNNLSTM(100, input_shape=input_shape, return_sequences=True))\n",
        "    model.add(tf.compat.v1.keras.layers.CuDNNLSTM(100, return_sequences=True))\n",
        "    model.add(tf.compat.v1.keras.layers.CuDNNLSTM(100))\n",
        "    model.add(tf.keras.layers.Dense(100, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(19, activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "model_lstm_1 = lstm_model_1(activation)\n",
        "model_lstm_1.summary()"
      ],
      "metadata": {
        "id": "6bjDTqGwyX4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batchsize = 100\n",
        "epochs = 100\n",
        "\n",
        "histlstm=model_lstm_1.fit(X_train1, Y_train, batch_size=batchsize, epochs=epochs, validation_data=(X_val1, Y_val), verbose=1)\n",
        "\n",
        "with open('/content/drive/My Drive/Colab Notebooks/PQ19/data/lstm1.pkl', 'wb') as file:  \n",
        "    pickle.dump(model, file)"
      ],
      "metadata": {
        "id": "DjIPdXd2yfYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(histlstm.history['loss'])\n",
        "plt.plot(histlstm.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper right')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(histlstm.history['accuracy'])\n",
        "plt.plot(histlstm.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WGFAOissynsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get the latest checkpoint file\n",
        "\n",
        "model_latest_checkpoint_lstm = create_model()\n",
        "# Load the previously saved weights\n",
        "model_latest_checkpoint_lstm.load_weights(checkpoint_path)"
      ],
      "metadata": {
        "id": "RCmQ_CLSyr4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_lstm = model_lstm_1.evaluate(X_test1, Y_test)\n",
        "print(\"Loss:\", acc_lstm[0], \" Accuracy:\", acc_lstm[1])\n",
        "\n",
        "pred = model_lstm_1.predict(X_test1)\n",
        "y_pred = pred.argmax(axis=-1)\n",
        "y_true = Y_test"
      ],
      "metadata": {
        "id": "R4_GHi3syutj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_classes=['C1','C2','C3','C4','C5','C6','C7','C8','C9','C10','C11','C12','C13','C14','C15','C16','C17','C18','C19']\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, classifier_name):\n",
        "    mtx = confusion_matrix(y_true, y_pred)\n",
        "    fig, ax = plt.subplots(figsize=(20,20))\n",
        "    ax.set_title(classifier_name)\n",
        "    sns.heatmap(mtx, xticklabels= output_classes, yticklabels=output_classes, cmap=\"Blues\", annot=True, fmt='d', linewidths=.5,  cbar=False, ax=ax)\n",
        "    #  square=True,\n",
        "    plt.ylabel('true label')\n",
        "    plt.xlabel('predicted label')"
      ],
      "metadata": {
        "id": "7vZG1BK6yw7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(y_true, y_pred, classifier_name='DLSTM')\n",
        "print(classification_report(y_true, y_pred,digits=4))\n",
        "acc_lstm1 = accuracy_score(y_true, y_pred)\n",
        "print(acc_lstm1)"
      ],
      "metadata": {
        "id": "VDwE1Gv5y1H1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DCNN+DLSTM"
      ],
      "metadata": {
        "id": "47TEGEdSjzZj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_rows = 40\n",
        "img_cols = 50\n",
        "\n",
        "X_train1 = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
        "X_val1 = X_val.reshape(X_val.shape[0], img_rows, img_cols, 1)\n",
        "X_test1 = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
        "print(X_train1.shape, X_val1.shape, X_test1.shape, Y_train.shape, Y_val.shape, Y_test.shape )\n",
        "\n",
        "input_shape = (img_rows, img_cols, 1)"
      ],
      "metadata": {
        "id": "P29u7Vxdj8zs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "activation='relu'\n",
        "\n",
        "def create_model():\n",
        "  cnnmodel = Sequential()   \n",
        "  cnnmodel.add(Conv2D(128, kernel_size=(3, 3), activation=activation, input_shape=input_shape)) \n",
        "  cnnmodel.add(MaxPooling2D(2,2))\n",
        "  cnnmodel.add(Conv2D(64, (3, 3), activation=activation))\n",
        "  cnnmodel.add(MaxPooling2D(2,2))\n",
        "  cnnmodel.add(Conv2D(64, kernel_size=(3, 3), activation=activation, input_shape=input_shape)) \n",
        "  cnnmodel.add(MaxPooling2D(2,2))\n",
        "  cnnmodel.add(Flatten())\n",
        "  \n",
        "  model = tf.keras.models.Sequential()\n",
        "  model.add(TimeDistributed(cnnmodel, ...))\n",
        "  model.add(tf.compat.v1.keras.layers.CuDNNLSTM(100, input_shape=input_shape, return_sequences=True))\n",
        "  model.add(tf.compat.v1.keras.layers.CuDNNLSTM(100, return_sequences=True))\n",
        "  model.add(tf.compat.v1.keras.layers.CuDNNLSTM(100))\n",
        "  model.add(tf.keras.layers.Dense(100, activation='relu'))\n",
        "  model.add(tf.keras.layers.Dense(19, activation='softmax'))\n",
        "\n",
        "  model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  return model\n"
      ],
      "metadata": {
        "id": "YSw2q4n8kHag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "model_ckpt= create_model()\n",
        "checkpoint_path = \"/content/drive/My Drive/Colab Notebooks/PQ19/data/chp19.ckpt\"\n",
        "cp_callback = ModelCheckpoint(filepath=checkpoint_path,save_best_only=True, save_weights_only=True, verbose=1)\n",
        "\n",
        "model_ckpt.summary()"
      ],
      "metadata": {
        "id": "265Uy4Q3lXp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batchsize = 100\n",
        "epochs = 1000\n",
        "\n",
        "hist=model_ckpt.fit(X_train1, Y_train, batch_size=batchsize, epochs=epochs, validation_data=(X_val1, Y_val),callbacks=[cp_callback], verbose=1)\n"
      ],
      "metadata": {
        "id": "qCAQtvi9lkiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')  \n",
        "plt.legend(['Train', 'Val'], loc='upper right')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(hist.history['accuracy'])\n",
        "plt.plot(hist.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "unwLITL8l74p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get the latest checkpoint file\n",
        "\n",
        "model_latest_checkpoint_lstm = create_model()\n",
        "# Load the previously saved weights\n",
        "model_latest_checkpoint_lstm.load_weights(checkpoint_path)"
      ],
      "metadata": {
        "id": "B383Oz8fmChO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_dcnnlstm = model_latest_checkpoint_lstm.evaluate(X_test1, Y_test)\n",
        "print(\"Loss:\", acc_lstm[0], \" Accuracy:\", acc_lstm[1])\n",
        "\n",
        "pred = model_latest_checkpoint_lstm.predict(X_test1)\n",
        "y_pred = pred.argmax(axis=-1)\n",
        "y_true = Y_test"
      ],
      "metadata": {
        "id": "O2zi0Hp-mGFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_classes=['C1','C2','C3','C4','C5','C6','C7','C8','C9','C10','C11','C12','C13','C14','C15','C16','C17','C18','C19']\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, classifier_name):\n",
        "    mtx = confusion_matrix(y_true, y_pred)\n",
        "    fig, ax = plt.subplots(figsize=(20,20))\n",
        "    ax.set_title(classifier_name)\n",
        "    sns.heatmap(mtx, xticklabels= output_classes, yticklabels=output_classes, cmap=\"Blues\", annot=True, fmt='d', linewidths=.5,  cbar=False, ax=ax)\n",
        "    #  square=True,\n",
        "    plt.ylabel('true label')\n",
        "    plt.xlabel('predicted label')"
      ],
      "metadata": {
        "id": "Zf4kffPQmS4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**WMV** weight updating"
      ],
      "metadata": {
        "id": "IuZR7e-ombl5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DCNNmostconfusedclasses=['C2','C10','C14','C16','C17','C18','C19']\n",
        "DCNNbestpredictedclasses=['C1','C3','C4','C5','C6','C7','C8','C11','C12','C13']\n",
        "DLSTMmostconfusedclasses=['C1','C7','C9']\n",
        "DLSTMbestpredictedclasses=['C2','C10','C15','C16','C17','C18','C19']\n",
        "DCNNLSTMmostconfusedclasses=['C4','C16','C17','C19']\n",
        "DCNNLSTMbestpredictedclasses=['C1','C7','C9','C10','C15']\n",
        "\n",
        "Wdcnn=1\n",
        "Wdlstm=1\n",
        "Wdcnnlstm = 1\n",
        "alphai=0.7\n",
        "\n",
        "predCNN = model_latest_checkpoint_cnn.predict(X_val1)\n",
        "predCNN = pred.argmax(axis=-1)\n",
        "\n",
        "predLSTM = model_latest_checkpoint_lstm.predict(X_val1)\n",
        "predLSTM = pred.argmax(axis=-1)\n",
        "\n",
        "predCNNLSTM = model_latest_checkpoint_cnnlstm.predict(X_val1)\n",
        "predCNNLSTM = pred.argmax(axis=-1)\n",
        "\n",
        "if predCNN in DCNNmostconfusedclasses :\n",
        "  Wdcnn=Wdcnn+alphai\n",
        "elif predCNN in DCNNbestpredictedclasses :\n",
        "  Wdcnn=Wdcnn-alphai\n",
        "else:\n",
        "  Wdcnn=Wdcnn\n",
        "\n",
        "if predLSTM in DLSTMmostconfusedclasses :\n",
        "  Wdlstm=Wdlstm+alphai\n",
        "elif predLSTM in DLSTMbestpredictedclasses :\n",
        "  Wdlstm=Wdlstm-alphai\n",
        "else:\n",
        "  Wdlstm=Wdlstm\n",
        "\n",
        "if predCNNLSTM in DCNNLSTMmostconfusedclasses :\n",
        "  Wdcnn=Wdcnn+alphai\n",
        "elif predCNNLSTM in DCNNLSTMbestpredictedclasses :\n",
        "  Wdcnn=Wdcnn-alphai\n",
        "else:\n",
        "  Wdcnn=Wdcnn\n"
      ],
      "metadata": {
        "id": "F-R5dd-dmayy"
      },
      "execution_count": 5,
      "outputs": []
    }
  ]
}